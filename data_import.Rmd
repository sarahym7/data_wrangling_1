---
title: "Data Import"
output: github_document
---


first load tidyverse library because the functions we are going to use exist in the package, more specific the readr


```{r setup}

library(tidyverse)

```


## Read in some data

Read in the litters data set. FYI read_csv is a function that exists in the readr's package
read_csv("write your relative path") so we read as "./from this starting point in folder datawrangling go to data folder and go into fas_litters.csv)

```{r}

litters_df = read_csv("./data/FAS_litters.csv")

```

Now cleaning data, this example has variables not in snakecase 
```{r}
litters_df= janitor::clean_names(litters_df)
```

to change the names we will use a certain function in a certain package -> janitor, we can also load package but doesnt matter bc we just want to use one function. 

## Take a look at the data 

Printing in the console.

```{r}
litters_df #running alone prints the data and see that the variables are now in snakecase

```
 
Can also use 

```{r}

head(litters_df) #gives you the first 6 rows

```


checking the tail gives you the info from the end
```{r}
tail(litters_df)
```

There are some gimick like the skimr. Gives you the min , max, histogram, just isnt used that frequent

```{r}
skimr::skim(litters_df)

```

View function, type in the console. will open a new window and allows to interact witht the dataset. Dont write view in the rmardown because can slow down the knitting.
view(litters_df)



when we print the litters_df function we will see that the group variable is a character, they are a mix of letters and numbers. A dbl is a particular kind of number, each column has numeric variables and the missing values are coded as NA. 


Additional options to read.csv -> ?read_csv, there are various uses 


# Options to read CSV

```{r}
litters_df = read_csv("./data/FAS_litters.csv", skip=10)
```
noticed that we have 39x8 instead of 49x8, its skipped the first 10 rows and taken whatever the first column as varibales names so instead we'll do 


```{r}
litters_df = read_csv("./data/FAS_litters.csv", skip=10, col_names = FALSE)
```

col_names=FALSE we use this to because we didn't provide r with column names so it will just create its own 
skip and col_name is useful when the csv provided is strangely structure like the first row is not columns, or there are blank information in the rows , or there is a description in the dataset that sometimes gets included in the first few rows so we can skip some rows or be clear theb first row interested are not column names it comes from somewhere else. 

other example 

```{r}


litters_df = read_csv("./data/FAS_litters.csv", na = c("", "NA", 999))

```
Anytime it sees this, r knows that they are missing values 



now column types which are guessed by read_csv, reads the first 1000 rows 
checkout `?read_csv()` for more info 

# New example

We have two excel files that we want to import and read in so we will be using these functions 


## Other file formats 
Read in an excel file 
1. create an mlb dataframe 
2. load read excel package , can put at top so person knows which packages will be used 

this is not in the readr package for csv but will function the same 
we need to give it the relative path , .= starting from the project home folder, wherever project is go into the data folder and find this dataset 

```{r}

library(readxl)

mlb_df = read_excel("./data/mlb11.xlsx")

mlb_df

```

dataset is already good with variable names 

FYI there are excel specific optionsin the read excel help file
sheet = NULL,
  range = NULL,
you have to specify which sheet you want to draw information from and specify the range of values you want to import from the columns

Example 

```{r}
read_excel("./data/mlb11.xlsx", range = "A1:F7")

```


#Reading in a SAS file


```{r}
library(haven) 

pulse_df = read_sas("./data/public_pulse_data.sas7bdat")

pulse_df

pulse_df = janitor::clean_names(pulse_df)
```

## Comparison with Base R


what about read.csv ? ->built into R and we dont have to load packages
never use read.csv ever bc very different than read_csv 

Heres why...

```{r}
litters_base = read.csv("data/FAS_litters.csv")
litters_readr = read_csv("data/FAS_litters.csv")

litters_base
litters_readr


```
Notice that litters_base will translate spaces to dots wheareas readrs is more easy manage 
the base is going to be more difficult to take a look at and the printed difference is the most obvious 
- readr is quicker and more consistent with the tidyverse 



## Exporting data 
want results of cleaned data to be exported 

so export the mlb subtable 
in write we have to tell it whats the thing we want to export and the path to give it 
```{r}
write_csv( mlb_df, "./data/mlb_subtable.csv")
```












